{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb7ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "MIMIC_DIR = \"mimic-iii-clinical-database-1.4\"\n",
    "\n",
    "con = duckdb.connect(\"mimic_local.duckdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1675555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Loading ICUSTAYS, PATIENTS, and ADMISSIONS...\n",
      "✅ Core tables loaded successfully.\n",
      "\n",
      "⚙️  Loading CHARTEVENTS (vital signs subset only)... this may take 5–10 minutes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d08cf6804147838b0cc1782dad2e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CHARTEVENTS (vitals only) loaded successfully.\n",
      "     n_rows\n",
      "0  31852450\n"
     ]
    }
   ],
   "source": [
    "print(\"⚙️  Loading ICUSTAYS, PATIENTS, and ADMISSIONS...\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE icustays AS\n",
    "SELECT * FROM read_csv_auto('{MIMIC_DIR}/ICUSTAYS.csv.gz');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE patients AS\n",
    "SELECT * FROM read_csv_auto('{MIMIC_DIR}/PATIENTS.csv.gz');\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE admissions AS\n",
    "SELECT * FROM read_csv_auto('{MIMIC_DIR}/ADMISSIONS.csv.gz');\n",
    "\"\"\")\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE d_items AS\n",
    "SELECT * FROM read_csv_auto('{MIMIC_DIR}/D_ITEMS.csv.gz');\n",
    "\"\"\")\n",
    "print(\"✅ Core tables loaded successfully.\\n\")\n",
    "\n",
    "# --- Step 2: Load only vital-sign rows from CHARTEVENTS ---\n",
    "print(\"⚙️  Loading CHARTEVENTS (vital signs subset only)... this may take 5–10 minutes.\")\n",
    "VITAL_ITEMIDS = [\n",
    "    # Heart Rate\n",
    "    211, 220045,\n",
    "    # Systolic BP\n",
    "    51, 442, 455, 220179, 220050,\n",
    "    # Diastolic BP\n",
    "    8368, 8440, 8502, 220180, 220051,\n",
    "    # Respiratory Rate\n",
    "    618, 220210,\n",
    "    # Temperature\n",
    "    223761, 676,\n",
    "    # SpO₂\n",
    "    646, 220277\n",
    "]\n",
    "itemid_list = \",\".join(map(str, VITAL_ITEMIDS))\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE chartevents AS\n",
    "SELECT *\n",
    "FROM read_csv_auto('{MIMIC_DIR}/CHARTEVENTS.csv.gz',\n",
    "                   all_varchar = true,\n",
    "                   sample_size = -1,\n",
    "                   ignore_errors = true)\n",
    "WHERE TRY_CAST(itemid AS INTEGER) IN ({itemid_list});\n",
    "\"\"\")\n",
    "print(\"✅ CHARTEVENTS (vitals only) loaded successfully.\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_rows FROM chartevents;\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14766a22-5fb0-43b4-ab9b-76fe9ea866d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️  Filtering for adult cohort (18-89 years, ≥12 hours ICU stay)...\n",
      "✅ Found 49689 adult ICU stays (≥12 hours).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Define adult cohort ---\n",
    "print(\"\\n⚙️  Filtering for adult cohort (18-89 years, ≥12 hours ICU stay)...\")\n",
    "def df_lower(query):\n",
    "    df = con.execute(query).df()\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "adult_cohort = df_lower(\"\"\"\n",
    "SELECT i.icustay_id,\n",
    "       i.subject_id,\n",
    "       i.hadm_id,\n",
    "       i.intime,\n",
    "       i.outtime,\n",
    "       a.ethnicity,\n",
    "       p.gender,\n",
    "       (EXTRACT(YEAR FROM i.intime) - EXTRACT(YEAR FROM p.dob)) AS age,\n",
    "       EXTRACT(EPOCH FROM (i.outtime - i.intime))/3600 AS los_hours\n",
    "FROM icustays i\n",
    "JOIN patients p USING (subject_id)\n",
    "JOIN admissions a USING (hadm_id)\n",
    "WHERE (EXTRACT(YEAR FROM i.intime) - EXTRACT(YEAR FROM p.dob)) BETWEEN 18 AND 89\n",
    "  AND EXTRACT(EPOCH FROM (i.outtime - i.intime))/3600 >= 12;\n",
    "\"\"\")\n",
    "adult_ids = adult_cohort[\"icustay_id\"].tolist()\n",
    "print(f\"✅ Found {len(adult_ids)} adult ICU stays (≥12 hours).\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e707e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Filtering CHARTEVENTS to adult cohort only...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e27e9c372c41b295773e7bff196294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered to adult ICU stays.\n",
      "     n_rows\n",
      "0  28766989\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Filter chartevents to adult cohort only ---\n",
    "print(\"⚙️  Filtering CHARTEVENTS to adult cohort only...\")\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE chartevents_adult AS\n",
    "SELECT * FROM chartevents\n",
    "WHERE TRY_CAST(icustay_id AS INTEGER) IN ({','.join(map(str, adult_ids))});\n",
    "\"\"\")\n",
    "print(\"✅ Filtered to adult ICU stays.\")\n",
    "print(con.execute(\"SELECT COUNT(*) AS n_rows FROM chartevents_adult;\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c76eb932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1da6bff40144d599156c9aba74b1804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert data types and handle nulls\n",
    "vitals_cleaned = df_lower(\"\"\"\n",
    "SELECT \n",
    "    TRY_CAST(icustay_id AS INTEGER) AS icustay_id,\n",
    "    TRY_CAST(itemid AS INTEGER) AS itemid,\n",
    "    charttime,\n",
    "    TRY_CAST(valuenum AS DOUBLE) AS valuenum,\n",
    "    valueuom\n",
    "FROM chartevents_adult\n",
    "WHERE valuenum IS NOT NULL \n",
    "  AND TRY_CAST(valuenum AS DOUBLE) IS NOT NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b864d97-3eb8-43c8-8a5c-194b7f23de31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for interpretability\n",
    "vital_mapping = {\n",
    "    'heart_rate': [211, 220045],\n",
    "    'sbp': [51, 442, 455, 220179, 220050],\n",
    "    'dbp': [8368, 8440, 8502, 220180, 220051],\n",
    "    'resp_rate': [618, 220210],\n",
    "    'temperature': [223761, 676],\n",
    "    'spo2': [646, 220277]\n",
    "}\n",
    "\n",
    "# Add vital_sign column\n",
    "def map_vital(itemid):\n",
    "    for vital, ids in vital_mapping.items():\n",
    "        if itemid in ids:\n",
    "            return vital\n",
    "    return 'unknown'\n",
    "\n",
    "vitals_cleaned['vital_sign'] = vitals_cleaned['itemid'].apply(map_vital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f26d81e-215a-4e7a-a5be-4796189d72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reasonable ranges\n",
    "ranges = {\n",
    "    'heart_rate': (0, 300),\n",
    "    'sbp': (0, 300),\n",
    "    'dbp': (0, 200),\n",
    "    'resp_rate': (0, 70),\n",
    "    'temperature': (20, 45),  # Celsius\n",
    "    'spo2': (0, 100)\n",
    "}\n",
    "\n",
    "# Filter outliers\n",
    "def is_valid(row):\n",
    "    vital = row['vital_sign']\n",
    "    value = row['valuenum']\n",
    "    if vital in ranges:\n",
    "        min_val, max_val = ranges[vital]\n",
    "        return min_val < value < max_val\n",
    "    return True\n",
    "\n",
    "vitals_cleaned = vitals_cleaned[vitals_cleaned.apply(is_valid, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a452542-adeb-4600-a42a-282ce8c04718",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: No function matches the given name and argument types '-(VARCHAR, TIMESTAMP)'. You might need to add explicit type casts.\n\tCandidate functions:\n\t-(TINYINT) -> TINYINT\n\t-(TINYINT, TINYINT) -> TINYINT\n\t-(SMALLINT) -> SMALLINT\n\t-(SMALLINT, SMALLINT) -> SMALLINT\n\t-(INTEGER) -> INTEGER\n\t-(INTEGER, INTEGER) -> INTEGER\n\t-(BIGINT) -> BIGINT\n\t-(BIGINT, BIGINT) -> BIGINT\n\t-(HUGEINT) -> HUGEINT\n\t-(HUGEINT, HUGEINT) -> HUGEINT\n\t-(FLOAT) -> FLOAT\n\t-(FLOAT, FLOAT) -> FLOAT\n\t-(DOUBLE) -> DOUBLE\n\t-(DOUBLE, DOUBLE) -> DOUBLE\n\t-(DECIMAL) -> DECIMAL\n\t-(DECIMAL, DECIMAL) -> DECIMAL\n\t-(UTINYINT) -> UTINYINT\n\t-(UTINYINT, UTINYINT) -> UTINYINT\n\t-(USMALLINT) -> USMALLINT\n\t-(USMALLINT, USMALLINT) -> USMALLINT\n\t-(UINTEGER) -> UINTEGER\n\t-(UINTEGER, UINTEGER) -> UINTEGER\n\t-(UBIGINT) -> UBIGINT\n\t-(UBIGINT, UBIGINT) -> UBIGINT\n\t-(UHUGEINT) -> UHUGEINT\n\t-(UHUGEINT, UHUGEINT) -> UHUGEINT\n\t-(BIGNUM) -> BIGNUM\n\t-(BIGNUM, BIGNUM) -> BIGNUM\n\t-(DATE, DATE) -> BIGINT\n\t-(DATE, INTEGER) -> DATE\n\t-(TIMESTAMP, TIMESTAMP) -> INTERVAL\n\t-(INTERVAL, INTERVAL) -> INTERVAL\n\t-(DATE, INTERVAL) -> TIMESTAMP\n\t-(TIME, INTERVAL) -> TIME\n\t-(TIMESTAMP, INTERVAL) -> TIMESTAMP\n\t-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE\n\t-(INTERVAL) -> INTERVAL\n\t-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE\n\t-(TIMESTAMP WITH TIME ZONE, TIMESTAMP WITH TIME ZONE) -> INTERVAL\n\n\nLINE 5:     EXTRACT(EPOCH FROM (v.charttime - i.intime))/3600 AS hours_from_admit\n                                            ^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Join with intime to calculate time from admission\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m vitals_with_time \u001b[38;5;241m=\u001b[39m df_lower(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    v.*,\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    i.intime,\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m    EXTRACT(EPOCH FROM (v.charttime - i.intime))/3600 AS hours_from_admit\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mFROM vitals_cleaned v\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mJOIN icustays i USING (icustay_id)\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Filter to first 24/48 hours if needed for early prediction\u001b[39;00m\n\u001b[1;32m     12\u001b[0m first_24h \u001b[38;5;241m=\u001b[39m vitals_with_time[vitals_with_time[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhours_from_admit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m24\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mdf_lower\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdf_lower\u001b[39m(query):\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(query)\u001b[38;5;241m.\u001b[39mdf()\n\u001b[1;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error: No function matches the given name and argument types '-(VARCHAR, TIMESTAMP)'. You might need to add explicit type casts.\n\tCandidate functions:\n\t-(TINYINT) -> TINYINT\n\t-(TINYINT, TINYINT) -> TINYINT\n\t-(SMALLINT) -> SMALLINT\n\t-(SMALLINT, SMALLINT) -> SMALLINT\n\t-(INTEGER) -> INTEGER\n\t-(INTEGER, INTEGER) -> INTEGER\n\t-(BIGINT) -> BIGINT\n\t-(BIGINT, BIGINT) -> BIGINT\n\t-(HUGEINT) -> HUGEINT\n\t-(HUGEINT, HUGEINT) -> HUGEINT\n\t-(FLOAT) -> FLOAT\n\t-(FLOAT, FLOAT) -> FLOAT\n\t-(DOUBLE) -> DOUBLE\n\t-(DOUBLE, DOUBLE) -> DOUBLE\n\t-(DECIMAL) -> DECIMAL\n\t-(DECIMAL, DECIMAL) -> DECIMAL\n\t-(UTINYINT) -> UTINYINT\n\t-(UTINYINT, UTINYINT) -> UTINYINT\n\t-(USMALLINT) -> USMALLINT\n\t-(USMALLINT, USMALLINT) -> USMALLINT\n\t-(UINTEGER) -> UINTEGER\n\t-(UINTEGER, UINTEGER) -> UINTEGER\n\t-(UBIGINT) -> UBIGINT\n\t-(UBIGINT, UBIGINT) -> UBIGINT\n\t-(UHUGEINT) -> UHUGEINT\n\t-(UHUGEINT, UHUGEINT) -> UHUGEINT\n\t-(BIGNUM) -> BIGNUM\n\t-(BIGNUM, BIGNUM) -> BIGNUM\n\t-(DATE, DATE) -> BIGINT\n\t-(DATE, INTEGER) -> DATE\n\t-(TIMESTAMP, TIMESTAMP) -> INTERVAL\n\t-(INTERVAL, INTERVAL) -> INTERVAL\n\t-(DATE, INTERVAL) -> TIMESTAMP\n\t-(TIME, INTERVAL) -> TIME\n\t-(TIMESTAMP, INTERVAL) -> TIMESTAMP\n\t-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE\n\t-(INTERVAL) -> INTERVAL\n\t-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE\n\t-(TIMESTAMP WITH TIME ZONE, TIMESTAMP WITH TIME ZONE) -> INTERVAL\n\n\nLINE 5:     EXTRACT(EPOCH FROM (v.charttime - i.intime))/3600 AS hours_from_admit\n                                            ^"
     ]
    }
   ],
   "source": [
    "# Join with intime to calculate time from admission\n",
    "vitals_with_time = df_lower(\"\"\"\n",
    "SELECT \n",
    "    v.*,\n",
    "    i.intime,\n",
    "    EXTRACT(EPOCH FROM (v.charttime - i.intime))/3600 AS hours_from_admit\n",
    "FROM vitals_cleaned v\n",
    "JOIN icustays i USING (icustay_id)\n",
    "\"\"\")\n",
    "\n",
    "# Filter to first 24/48 hours if needed for early prediction\n",
    "first_24h = vitals_with_time[vitals_with_time['hours_from_admit'].between(0, 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb0e29-5185-47d9-8bf4-53d3d2a4d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get summary statistics per ICU stay\n",
    "vitals_summary = vitals_with_time.groupby(['icustay_id', 'vital_sign'])['valuenum'].agg([\n",
    "    'mean', 'std', 'min', 'max', 'count'\n",
    "]).reset_index()\n",
    "\n",
    "# Pivot to wide format\n",
    "vitals_wide = vitals_summary.pivot(\n",
    "    index='icustay_id',\n",
    "    columns='vital_sign',\n",
    "    values=['mean', 'std', 'min', 'max']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1980ca4b-4131-47ba-af8d-2b4f688eca4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1086eac70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE d_items AS\n",
    "SELECT * FROM read_csv_auto('{MIMIC_DIR}/D_ITEMS.csv.gz');\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7184b715-6a6f-442b-a0fc-03ef42605619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 vent-related ITEMIDs collected.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m ids_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, VENT_ITEMIDS))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(VENT_ITEMIDS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vent-related ITEMIDs collected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m ids_csv\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold_vent_itemids.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids_csv)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vent-related items to vent_itemids_labels_filtered.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "vent_ids = con.execute(\"\"\"\n",
    "WITH candidates AS (\n",
    "  SELECT\n",
    "    CAST(itemid AS INTEGER) AS itemid,\n",
    "    lower(coalesce(label, ''))    AS lab,\n",
    "    lower(coalesce(category, '')) AS cat\n",
    "  FROM d_items\n",
    "),\n",
    "hits AS (\n",
    "  SELECT DISTINCT itemid\n",
    "  FROM candidates\n",
    "  WHERE\n",
    "    lab LIKE '%vent%' OR cat LIKE '%vent%'\n",
    "    OR lab LIKE '%mechanical vent%' OR lab LIKE '%ventilator mode%'\n",
    "    OR lab LIKE '%intubat%' OR lab LIKE '%extubat%'\n",
    "    OR lab LIKE '%peep%' OR lab LIKE '%psv%'\n",
    "    OR lab LIKE '%pip%' OR lab LIKE '%plateau%'\n",
    "    OR lab LIKE '%tidal vol%' OR lab LIKE '%vt%'\n",
    "    OR lab LIKE '%fio2%' OR lab LIKE '%inspired o2%'\n",
    "    OR lab LIKE '%minute vent%' OR lab LIKE '%rr set%'\n",
    ")\n",
    "SELECT itemid\n",
    "FROM hits\n",
    "ORDER BY itemid;\n",
    "\"\"\").df()\n",
    "\n",
    "\n",
    "vent_ids.columns = [c.strip().lower() for c in vent_ids.columns]\n",
    "\n",
    "VENT_ITEMIDS = vent_ids[\"itemid\"].astype(int).tolist()\n",
    "ids_csv = \",\".join(map(str, VENT_ITEMIDS))\n",
    "print(f\"{len(VENT_ITEMIDS)} vent-related ITEMIDs collected.\")\n",
    "ids_csv.to_csv(\"old_vent_itemids.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77b679d4-69b6-4756-8796-efc6c310aa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 313  vent-related items to vent_itemids_labels_filtered.csv\n",
      "Saved 98 filtered vent-related items to vent_itemids_labels_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "vent_labels = con.execute(f\"\"\"\n",
    "SELECT itemid, label\n",
    "FROM d_items\n",
    "WHERE itemid IN ({ids_csv})\n",
    "ORDER BY itemid;\n",
    "\"\"\").df()\n",
    "\n",
    "vent_labels.to_csv(\"vent_itemids.csv\", index=False)\n",
    "print(f\"Saved {len(vent_labels)}  vent-related items to vent_itemids_labels_filtered.csv\")\n",
    "\n",
    "all_exclusions = (\n",
    "    # Generic/False Positive Filter (Parentheses escaped)\n",
    "    \"intervent|ventric|combivent|flovent|piperacillin|atrovent|prevent|event|advent|conven|\"\n",
    "    \"esdep|floor|or sent|or received|defibrillation|pneumothorax|operation|fluoroscopy|nuclear|fall|brain death|timeout|\"\n",
    "    \"hand cleansing|barrier precautions|no complications|\"\n",
    "    \"attending|supervisor|checklist|gcsverbal|apache|patient identified|identified correctly|\"\n",
    "    \"transferred|transfer|temporary ventricular|temporary pacemaker|pacer wires|stim thresh|sens thresh|\"\n",
    "    \"vent drain|ventric|cpp|icp|cap|flowvent|chest pain|cardiac arrest|respiratory arrest|chest opened|line/catheter removal|peritoneal fluid|c-spine|tls clearance|\"\n",
    "    \n",
    "    # Airway Management Procedures (DROP)\n",
    "    \"intubat|extubat|ett|tube secured|stylette|bougie|larynx|laryng|mask vent|rsi|\"\n",
    "    \"pre-oxygen|difficult to intubat|induction|drugs|thyromental|mandibular|dentition|neck rom|airway assessment|\"\n",
    "    \"propofol|ketamine|etomidate|vecuronium|cis-atracurium|succ|pre-oxy|blade|equipment|\"\n",
    "    \n",
    "    # Measurements/Observed Values (DROP: Note the proper escaping of parentheses)\n",
    "    \"measured|observ|spont|tidal volume \\\\(ml\\\\)|vt \\\\(ml\\\\)|volume measured|\"\n",
    "    \"peep observed|p-peak observed|pi observed|pmean observed|p mean observed|\"\n",
    "    \"etco2|p_exp|exp flow|exp volume|exp vt|\"\n",
    "    \"insp flow|inspiratory flow|p insp|p_insp|flow measured|tidal volume measured|\"\n",
    "    \"vent rate observed|resp rate observed|min vent measured|minute vol observed|flow \\\\(l/s\\\\)|\" # Flow (l/s) escaped\n",
    "    \n",
    "    # Alarm Settings (DROP)\n",
    "    \"alarm|low|high|apnea|apnoea|\"\n",
    "    \n",
    "    # Secondary/Derived Values (DROP)\n",
    "    \"ratio|i:e ratio|vd/vt|ie ratio|compliance|resistance|trigger|trigger flow\"\n",
    ")\n",
    "\n",
    "# Apply the filter with regex=True to utilize the '|' operator correctly\n",
    "# and case=False for case-insensitive matching.\n",
    "vent_labels_filtered = vent_labels[\n",
    "    ~vent_labels[\"LABEL\"].str.contains(\n",
    "        all_exclusions,\n",
    "        case=False,\n",
    "        na=False,\n",
    "        regex=True # Confirms the string is a regex, resolves the warning\n",
    "    )\n",
    "]\n",
    "\n",
    "vent_labels_filtered.to_csv(\"vent_itemids_labels_filtered.csv\", index=False)\n",
    "print(f\"Saved {len(vent_labels_filtered)} filtered vent-related items to vent_itemids_labels_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aca4d83-9fc6-4b6e-bc82-0672f40cfc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded file: new_snap_lookback12_horizon12.csv\n",
      "The number of '1's in the column 'y_vent_in_horizon' is: 26089\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path and the target column name\n",
    "file_path = \"new_snap_lookback12_horizon12.csv\"\n",
    "\n",
    "column_name = \"y_vent_in_horizon\"\n",
    "\n",
    "try:\n",
    "    # 1. Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Check if the column exists\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Error: Column '{column_name}' not found in the CSV file.\")\n",
    "        print(\"Available columns are:\", list(df.columns))\n",
    "    else:\n",
    "        # 3. Count the number of times the value '1' appears in the specified column\n",
    "        # .value_counts() returns a series of counts for unique values.\n",
    "        # .get(1, 0) retrieves the count for the value 1, or 0 if 1 is not present.\n",
    "        count_of_ones = df[column_name].value_counts().get(1, 0)\n",
    "        \n",
    "        # 4. Print the result\n",
    "        print(f\"Successfully loaded file: {file_path}\")\n",
    "        print(f\"The number of '1's in the column '{column_name}' is: {count_of_ones}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "    print(\"Please ensure the file is in the correct directory or update the 'file_path'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf58f3-5984-4c72-beac-ffdf69c0ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
